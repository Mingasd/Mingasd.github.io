---
layout: post
title: 面经盘点
data: 2022-03-11
tags: [面经]
---

### SYN泛洪

SYN泛洪攻击(SYN Flood)是一种比较常用的DoS（拒绝服务）方式之一，通过发送大量伪造的Tcp连接请求，使被攻击主机资源耗尽(通常是CPU满负荷或者内存不足)。

我们都知道建立Tcp连接需要完成三次握手。正常情况下客户端首先向服务端发送SYN报文，随后服务端回以SYN+ACK报文到达客户端，最后客户端向服务端发送ACK报文完成三次握手。

SYN泛洪攻击则是客户端向服务器发送SYN报文之后就不再响应服务器回应的报文。由于服务器在处理TCP请求时，会**在协议栈留一块缓冲区来存储握手的过程**，如果客户端没有发送一个ACK来完成三次握手的第三步，最终（通常一分钟或更久以后）服务器会终止这个半开的连接并收回分配的资源。攻击者发送大量的TCP SYN报文段，不完成第三次握手的步骤。随着SYN报文段的大量涌入，服务器的连接资源在分配给（但从未使用）半开连接时会耗尽。然后合法的用户就被拒绝服务了。

如何防范：

1. 降低SYN timeout时间，使得主机尽快释放半连接的占用。
2. 采用SYN cookie设置，当服务器收到SYN报文段时，**不为此创建半连接**，而是向客户端发送带有特殊序列号的SYNACK报文段，初始序列就是**cookie = hash(src_ip, dest_ip, src_port, dest_port, secret_number)**，当客户端返回ACK报文段时，利用相同的hash算法计算是否与确认字段相同，通过后才会创建一个全打开的连接。



### 如何保证Redis高并发、高可用

其实问这个问题，主要是redis 单机能承载多高并发？如果单机扛不住如何扩容扛更多的并发？redis 会不会挂？既然 redis 会挂那怎么保证 redis 是高可用的？

#### redis 主从架构保证高并发

单机的 redis，能够承载的 QPS(query per second) 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。

![](https://gitee.com/wecouldwin/blog-imag/raw/master/img/20220311122643.png)

主从同步：从2.8版本开始Redis使用psyn命令完成主从数据同步，同步过程分为全量辅助和部分复制。

1. 当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。如果这是 slave node 初次连接到 master node，那么会触发一次全量复制。
2. 部分复制用于如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。

#### redis 哨兵集群实现高可用

哨兵是 redis 集群机构中非常重要的一个组件，哨兵节点也独立的Redis节点，它不存储数据只支持部分命令，作为一个哨兵集群去运行，互相协同工作，即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，保证了自己的健壮性，主要有以下功能：

- 集群监控：负责监控 redis master 和 slave 进程是否正常工作。
- 消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
- 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。
- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。



### DNS是什么，用了什么协议，DNS劫持是什么

DNS域名解析协议，将域名转化为ip地址。DNS服务器有着相当全的域名和IP，当你输入一串网站的时候，先将这个网站发送给DNS服务器，DNS服务器帮你把这串网站变成了IP地址，再访问这个IP地址。

DNS在区域传输的时候使用TCP协议，域名解析时候使用UDP协议。

1. 辅域名服务器会定时（一般3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，会执行一次区域传送，进行数据同步。区域传送使用TCP而不是UDP，因为数据同步传送的数据量比一个请求应答的数据量要多得多。
2. 客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过三次握手，这样DNS服务器负载更低，响应更快。

DNS劫持：在DNS服务器中，将域名对应的IP地址进行了变化。你解析出来的域名对应的IP，在劫持前后不一样。



### 装载进程、运行进程的全过程

#### 装在方式

程序执行时所需要的指令和数据必须在内存中才能够正常运行，但是一般情况下程序所需内存远大于物理内存。为了解决这个问题，有两种装载方式，`覆盖装入(Overlay)`和`页映射(Paging)`。

1. 覆盖装入：核心思想是将程序的模块进行分割，如果两个模块不会相互调用，那么两个模块可以共享同一段空间，用谁就加载谁。
2. 页映射：主要策略是将物理内存划分成页，而虚拟地址也被分成页，这两个页间可以定义一种映射关系，虚存与物存的映射方式、数据存储、替换方法都由内存管理单元MMU完成。

#### 进程的建立

这个过程分为三步

- 创建虚拟地址空间：创建虚拟地址空间其实不是真的把一段空间抹成什么值，而是仅仅分配一个数据结构，在linux下仅仅时分配一个页表`(Page Directory)`
- 读取可执行文件头，建立虚拟空间与可执行文件的映射关系
- 将CPU指令寄存器设置成可执行文件入口，启动运行。



### 进程切换主要切换哪些内容

进程切换时需要刷新TLB(快表, 页表的Cache)并获取新的地址空间，然后切换硬件上下文和内核栈。

切换进程时必须考虑保存当前进程的状态，包括放在内存中的程序代码和数据，栈、通用目的寄存器内容、程序计数器、环境变量等，这个状态成为上下文。由于虚拟内存机制，进程切换时需要刷新TLB并获取新的地址空间。



### HTTP 1.0、1.1、2.0和3的区别

####  1.0与1.1差别

1. 增加了缓存处理，引入更多的缓存控制策略
2. 带宽优化及网络连接的使用：在**请求头引入了range头域**，它允许只请求资源的某个部分，即**返回码是206**（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
3. 增加了24个错误状态响应码
4. 在HTTP1.1中默认开启`Connection：keep-alive`，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

#### 2.0的改变

1. HTTP1.x是基于文本的，HTTP2.0的协议解析决定采用二进制格式。
2. 多路复用：每一个request 都可以共享同一个连接
3. Header头压缩
4. 推荐TLS连接，且对其算法安全性有强制要求

#### 3.0

1. 使用了UDP，并自己定义了可靠传输，乱序重组，窗口拥塞算法等算法，这样就绕开了TCP的拥塞和慢启动等问题。
2. 定义了一套单包握手的SSL协议，这样就绕开了TLS1.2的4次握手问题。
3. 头部压缩优化算法



### Redis异步消息队列和时延队列

Redis通过`list`数据结构来实现消息队列，当队列长时间为空时，使用`blpop/brpop` 来阻塞读取队列。会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。

时延队列：我们可以将有序集合的value设置为我们的消息任务，把value的score设置为消息的到期时间，然后轮询获取有序集合的中的到期消息进行处理。



### MySQL在可重复读隔离级别为什么会出现幻读

mysql在select中启用mvcc，使用原始快照，其读取的数据时快照中的，即使在读的过程中数据被删除或者增加，依旧没有问题。

但是对数据进行修改的操作(update、insert、delete)都是采用当前读的模式，这部分会读取最近的记录，出现幻读的问题。

解决幻读 MVCC+next-key locks



### 线程池构造参数与饱和策略

**`ThreadPoolExecutor` 3 个最重要的参数：**

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

`ThreadPoolExecutor`其他常见参数 :

1. **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
2. **`unit`** : `keepAliveTime` 参数的时间单位。
3. **`threadFactory`** :executor 创建新线程的时候会用到。
4. **`handler`** :饱和策略。

**`ThreadPoolExecutor` 饱和策略定义:**

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，`ThreadPoolTaskExecutor` 定义一些策略:

- **`ThreadPoolExecutor.AbortPolicy`** ：抛出 `RejectedExecutionException`来拒绝新任务的处理。这也是**默认**的饱和策略
- **`ThreadPoolExecutor.DiscardPolicy`** ：不处理新任务，直接丢弃掉。
- **`ThreadPoolExecutor.DiscardOldestPolicy`** ： 此策略将丢弃最早的未处理的任务请求。
- **`ThreadPoolExecutor.CallerRunsPolicy`** ：调用执行自己的线程运行任务



### redis集群模式有几种

主从复制、哨兵模式、redis-cluster集群

redis-cluster集群：在redis3.0上加入了cluster模式，实现的redis的分布式存储，也就是说每台redis节点上存储不同的内容。

 Redis-Cluster采用无中心结构,它的特点如下：

- 所有的redis节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。
- 节点的fail是通过集群中超过半数的节点检测失效时才生效。
- 客户端与redis节点直连，不需要中间代理层.客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。

